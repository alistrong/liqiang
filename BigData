1.hadoop的简介
hadoop 是由HDFS,mapReduce,zookeeper,HBase,hive几部分组成，最基础最重要的元素是用于存储底层节点文件的分布式文件系统HDFS和用于计算处理的mapReduce引擎
hive是基于Hadoop的工具，提供完整的sql查询，将sql语句转化成mapReduce处理
HBase是基于列储存的分布式数据库
ZooKeeper是高效可拓展的协调系统，存储和协调关键共享状态
HDFS是高容错的分布式文件系统，典型的主从模式，nameNode和多个datanode,namenode负责整个系统的文件的元数据信息的管理，集群中通常只有一台机器运行namenode
实例，DataNode存储文件中的数据，集群中的机器分别运行一个datanode实例，名称节点和数据节点通过心跳机制进行定时通信。
namenode主要负责管理分布式文件的命名空间，集群的配置信息，存储块的复制
datanode主要存储meta_date，同时周期性的向namenode发送所有存在的文件块的报告。
mapReduce:采用分治的思想，把任务分发到集群的各个节点，然后多个节点并行处理，最后汇总各个处理结果得到最终结果，输入块把数据分割成小的数据块，传给map节点，
map节点根据得到的key/value处理得到多个或者1个key/value写入临时文件，reduce根据临时文件的数据，对相同key的进行迭代计算，最后得到最终结果。


海量数据处理

1 给定a,b两个文件，各存放50亿个url，每个url占64B，内存限制是4G，找出a,b文件共同的URL

5000000000 * 64B == 320GB
由于内存有限，我们不可能一次性把所有URL加载到内存中，一般采用分治策略，把一个文件的URL按照某种特征划分几个小文件，使得每个小文件不超过4G，这样就可以把小文件读到内存中进行处理

思路如下：
遍历文件a，对遍历的URL求hash(url)%1000,把对应url存储到a0,a1,a2,...,a999，这样每个大小约为300MB，同样方式处理文件b，接着对这1000对小文件做处理即可。
接着遍历小文件ai 把URL存储到一个HashSet集合中，遍历bi中每个URL，看是否在HashSet集合中是否存在，存在就是共同URL，把这些url保存到一个单独文件

2 一个1GB大小文件，文件每一行是一个单词，每个词大小不超过16B，内存大小限制1MB，返回频率最高的100个词。

由于内存限制，依然无法直接将大文件所有词一次性读入到内存中，采用分支策略，把一个大文件分解小文件，保证每个小文件大小小于1MB，将小文件读入内存处理

思路如下：
遍历大文件，对遍历到的每次词，进行hash(x)%5000,得到5000个小文件，大小约为200KB，
接着统计每个小文件出现频率最高的100个词，使用HashMap,key是单词，value是单词出现的频率
再往下我们维护小（大）顶堆找出top100,

3 在2.5亿个整数中找出不重复的整数，内存不足容纳2.5亿个整数

思路：
位图，可以用一个或者多个bit来标记某个元素对应的值，而键就是该元素，采用位作为单位来存储数据，大大节省存储空间
例如6,4,2,1,5 采用位图法， 0-7范围总共有8个数，只需要8bit， 0 0 0 0 0 0 0 0 
假设int整数占用4B，即32bit，我们可以表示的整数的个数是2^32
对于这道题，我们用2bit表示各个数的状态
00 没有出现过
01 表示只出现一次
10 表示出现了多次

2^32个整数，所需内存是 2^32 * 2b = 1GB, 当可用内存超过1GB，可用位图法。
遍历2.5亿个整数，查看位图中对应的位，如果是00 ，则变成01，如果是01，则变成10，如果是10，保持不变。
然后查看位图，把对应位是01的整数输出即可








